{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqtoPKmaXuts"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FnkABiyYxoz"
   },
   "outputs": [],
   "source": [
    "mnist_dataframe = pd.read_csv(\n",
    "  \"https://download.mlcc.google.com/mledu-datasets/mnist_train_small.csv\",\n",
    "  sep=\",\",\n",
    "  header=None)\n",
    "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuEiSp_qZA1I"
   },
   "outputs": [],
   "source": [
    "# parse data\n",
    "def label_feature(dataframe):\n",
    "  labels = np.matrix.transpose(np.matrix(dataframe.iloc[:,0]))\n",
    "  features = np.matrix(dataframe.iloc[:,1:785])\n",
    "  features = features/255  # feature scaling\n",
    "  return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd2S6g1TiylW"
   },
   "outputs": [],
   "source": [
    "# parse label data\n",
    "\n",
    "def one_hot(oringinal_label):\n",
    "  datalength = len(oringinal_label)\n",
    "  label = np.zeros([datalength,10])\n",
    "  for i in range(len(oringinal_label)):\n",
    "    index = oringinal_label[i] \n",
    "    label[i,index]=1\n",
    "    \n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa5bWV2EwHBv"
   },
   "outputs": [],
   "source": [
    "t_label, train_feature = label_feature(mnist_dataframe.iloc[0:15000,:])\n",
    "v_label, validation_feature = label_feature(mnist_dataframe.iloc[15000:20000,:])\n",
    "train_label = one_hot(t_label)\n",
    "validation_label = one_hot(v_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9lrcwTpxMrO"
   },
   "outputs": [],
   "source": [
    "# hidden layer\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size],stddev=0.01))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs, Weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NATMgbdhMRA8"
   },
   "outputs": [],
   "source": [
    "# define accuracy\n",
    "def accuracy(label, prediction):\n",
    "  correct = 0\n",
    "  labidx = np.argmax(label, axis=1)\n",
    "  prdidx = np.argmax(prediction, axis=1)\n",
    "  for i in range(len(labidx)):\n",
    "    if labidx[i]==prdidx[i]:\n",
    "       correct += 1\n",
    "      \n",
    "  return correct/len(labidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the structure of neural network and the placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWOJEJ1iztRx"
   },
   "outputs": [],
   "source": [
    "InputNeurons = 784\n",
    "OutputNeurons = 10\n",
    "train_keep = 0.65  # dropout parameter, keep how many percentage\n",
    "learning_rate = 0.01\n",
    "printstep = 50\n",
    "traing_epochs = 701\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, InputNeurons])\n",
    "ys = tf.placeholder(tf.float32, [None, OutputNeurons])\n",
    "\n",
    "# add hidden layer\n",
    "[l1,W1,b1] = add_layer(xs, InputNeurons, 100, activation_function=tf.nn.relu)\n",
    "[l2,W2,b2] = add_layer(l1,100,100,activation_function=tf.nn.relu)\n",
    "[l3,W3,b3] = add_layer(l2,100,100,activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "[prediction,Wp,bp] = add_layer(l3, 100, OutputNeurons, activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), axis=1))\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ys,logits=prediction,dim=-1)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# start of the neural network\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "7vHWGBjS4c8x",
    "outputId": "5591c961-8909-42f6-ac54-41c1730f0e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 validation loss= [2.2965686 2.2965665 2.2973008 ... 2.3062768 2.310087  2.3125663] Train Loss= [2.306294  2.3137279 2.2965646 ... 2.2965746 2.2988396 2.3125706]\n",
      "epoch 50 validation loss= [2.1509519 2.1362724 2.2917955 ... 2.2342858 2.238496  2.392982 ] Train Loss= [2.4568686 2.2652667 2.1033313 ... 2.1845195 2.2600987 2.2338734]\n",
      "epoch 100 validation loss= [1.7500379 1.8982992 2.4250584 ... 1.5752904 1.7837152 2.4185586] Train Loss= [2.4611082 2.1052418 1.6980841 ... 1.9705143 1.4710073 1.5835495]\n",
      "epoch 150 validation loss= [1.5288023 1.8273284 2.3399127 ... 1.4646567 1.4620188 2.4513958] Train Loss= [2.4611266 1.629505  1.5105472 ... 1.6362561 1.4632534 1.4674755]\n",
      "epoch 200 validation loss= [1.4706869 1.5040737 1.7086388 ... 1.4613745 1.4612246 2.4537241] Train Loss= [2.4611354 1.4663463 1.4673867 ... 1.5496904 1.4614002 1.4612685]\n",
      "epoch 250 validation loss= [1.4644877 1.4764948 1.5118095 ... 1.461173  1.4612318 2.4597223] Train Loss= [2.4611464 1.461176  1.4635274 ... 1.479248  1.4611901 1.4611799]\n",
      "epoch 300 validation loss= [1.4615417 1.4640937 1.4867725 ... 1.4611528 1.461179  2.4590895] Train Loss= [2.4611497 1.4611509 1.4614791 ... 1.4649141 1.4611669 1.4611565]\n",
      "epoch 350 validation loss= [1.4612306 1.4621329 1.474128  ... 1.4611505 1.4611706 2.4580479] Train Loss= [2.46115   1.46115   1.4612632 ... 1.4618952 1.4611658 1.4611527]\n",
      "epoch 400 validation loss= [1.4611733 1.4614831 1.4689792 ... 1.4611503 1.4611698 2.4527092] Train Loss= [2.4611502 1.46115   1.461185  ... 1.4613774 1.4611573 1.4611511]\n",
      "epoch 450 validation loss= [1.4611621 1.4613426 1.4677869 ... 1.4611502 1.4611592 2.4203944] Train Loss= [2.4611502 1.46115   1.4611701 ... 1.4612797 1.4611547 1.4611506]\n",
      "epoch 500 validation loss= [1.461156  1.4612869 1.4655054 ... 1.4611502 1.461158  2.4319537] Train Loss= [2.4611502 1.46115   1.461164  ... 1.4612403 1.4611533 1.4611504]\n",
      "epoch 550 validation loss= [1.4611542 1.4612675 1.4644716 ... 1.4611502 1.4611565 2.439484 ] Train Loss= [2.4611502 1.46115   1.4611636 ... 1.4612168 1.4611526 1.4611503]\n",
      "epoch 600 validation loss= [1.4611522 1.4612373 1.4659939 ... 1.4611502 1.4611542 2.454426 ] Train Loss= [2.4611502 1.46115   1.4611574 ... 1.461185  1.4611517 1.4611503]\n",
      "epoch 650 validation loss= [1.4611515 1.4612337 1.4623958 ... 1.4611502 1.4611574 2.4518623] Train Loss= [2.4611502 1.46115   1.4611557 ... 1.4611729 1.4611515 1.4611503]\n",
      "epoch 700 validation loss= [1.4611512 1.4612097 1.4626666 ... 1.4611502 1.4611558 2.451733 ] Train Loss= [2.4611502 1.46115   1.4611547 ... 1.4611659 1.4611512 1.4611502]\n",
      "train_accuracy= 0.9675333333333334\n",
      "validation_accuracy= 0.9366\n"
     ]
    }
   ],
   "source": [
    "for i in range(traing_epochs):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: train_feature, ys: train_label, keep_prob: train_keep})\n",
    "    if i % printstep == 0:\n",
    "        # to see the step improvement\n",
    "        train_loss = sess.run(loss, feed_dict={xs: train_feature, ys: train_label, keep_prob: 1})\n",
    "        validation_loss = sess.run(loss, feed_dict={xs: validation_feature, ys: validation_label, keep_prob:1})\n",
    "        print(\"epoch\",i,\"validation loss=\", validation_loss,\"Train Loss=\",train_loss)\n",
    "    \n",
    "    \n",
    "train_output = sess.run(prediction, feed_dict={xs: train_feature, ys: train_label, keep_prob: 1})\n",
    "train_accuracy = accuracy(train_label, train_output)\n",
    "validation_output = sess.run(prediction, feed_dict={xs: validation_feature, ys: validation_label, keep_prob: 1})\n",
    "validation_accuracy = accuracy(validation_label, validation_output)\n",
    "print('train_accuracy=',train_accuracy)\n",
    "print('validation_accuracy=', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTl9pnvRDrq3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KenVersion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
